{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb569d95",
   "metadata": {},
   "source": [
    "# Sprawozdanie - Lab 4\n",
    "\n",
    "## Autor: Wiktor Sędzimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77f9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "376753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_execution_time(function, *data):\n",
    "    return timeit.timeit(lambda: function(*data), number=1)\n",
    "\n",
    "def get_rand_lowercase_char():\n",
    "    return chr(ord('a') + random.randint(0, 25))\n",
    "\n",
    "def get_random_text(size: int):\n",
    "    return ''.join((get_rand_lowercase_char() for _ in range(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cc85c",
   "metadata": {},
   "source": [
    "## Zadanie algorytm Ukkonena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da44593",
   "metadata": {},
   "source": [
    "#### Analiza złożoności\n",
    "\n",
    "Dzięki zastosowaniu optymalizacji:\n",
    "1. Technika skip/count\n",
    "2. Reguła 3 (reguła łącza sufiksowego)\n",
    "3. Technika wskaźnika końcowego\n",
    "\n",
    "Moja implementacja algorytmu Ukkonena ma złożoność liniową ```O(n)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339f8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional\n",
    "from collections import deque\n",
    "\n",
    "class IntRef:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "class Node:\n",
    "    text: str = \"\"\n",
    "    def __init__(self, end: IntRef, start: int = -1, id: int = -1, suffix_link: Optional[Node] = None):\n",
    "        self.children: dict[str, Node] = {}\n",
    "        self.suffix_link: Optional[Node] = suffix_link\n",
    "        self.start: int = start\n",
    "        self.end: IntRef = end\n",
    "        self.id: int = id\n",
    "\n",
    "    def width(self):\n",
    "        return self.end.value - self.start + 1\n",
    "\n",
    "    def debug_str(self):\n",
    "        return f\"Node(\\\"{self.text[self.start:self.end.value + 1]}\\\", start: {self.start}, end: {self.end.value} id: {self.id}, link: {self.suffix_link})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Node(\\\"{self.text[self.start:self.end.value + 1]}\\\")\"\n",
    "\n",
    "class SuffixTree:\n",
    "    def __init__(self, text: str):\n",
    "        \"\"\"\n",
    "        Construct a suffix tree for the given text using Ukkonen's algorithm.\n",
    "\n",
    "        Args:\n",
    "            text: The input text for which to build the suffix tree\n",
    "        \"\"\"\n",
    "        self.guardian: str = \"$\"\n",
    "        self.end_ref: IntRef = IntRef(0)\n",
    "        self.text: str = text + self.guardian\n",
    "        self.root: Node = Node(IntRef(-1), start=0)\n",
    "        self.active_node: Node = self.root\n",
    "        self.active_edge: int = 0\n",
    "        self.active_length: int = 0\n",
    "        self.remainder: int = 0\n",
    "        self.leaf_id: int = 0\n",
    "        self.inner_node_cnt: int = 0\n",
    "\n",
    "        Node.text = self.text\n",
    "\n",
    "        self.build_tree()\n",
    "\n",
    "        self.leaf_cnt = self.leaf_id\n",
    "\n",
    "    def build_tree(self):\n",
    "        \"\"\"\n",
    "        Build the suffix tree using Ukkonen's algorithm.\n",
    "        \"\"\"\n",
    "        text_len = len(self.text)\n",
    "        self.remainder = 0\n",
    "\n",
    "        for i in range(text_len):\n",
    "            self.extend_tree(i)\n",
    "\n",
    "    def get_node_first_char(self, node: Node):\n",
    "        return self.text[node.start]\n",
    "\n",
    "    def add_child_node(self, parent: Node, child: Node):\n",
    "        parent.children[self.get_node_first_char(child)] = child\n",
    "\n",
    "    def get_current_child(self):\n",
    "        return self.active_node.children[self.get_active_edge_char()]\n",
    "\n",
    "    def get_active_edge_char(self):\n",
    "        return self.text[self.active_edge]\n",
    "\n",
    "    def create_leaf(self, start: int):\n",
    "        leaf = Node(end = self.end_ref, start = start, id = self.leaf_id)\n",
    "        self.leaf_id += 1\n",
    "\n",
    "        return leaf\n",
    "\n",
    "    def extend_tree(self, position):\n",
    "        self.end_ref.value = position\n",
    "        curr_char = self.text[position]\n",
    "        last_added_node: Optional[Node] = None\n",
    "        self.remainder += 1\n",
    "\n",
    "        while self.remainder > 0:\n",
    "            if self.active_length == 0:\n",
    "                self.active_edge = position\n",
    "\n",
    "            if self.get_active_edge_char() not in self.active_node.children:\n",
    "                new_leaf = self.create_leaf(position)\n",
    "                self.add_child_node(self.active_node, new_leaf)\n",
    "\n",
    "                if last_added_node is not None:\n",
    "                    last_added_node.suffix_link = self.active_node\n",
    "                    last_added_node = None\n",
    "            else:\n",
    "                curr_child = self.get_current_child()\n",
    "                idx = curr_child.start + self.active_length\n",
    "\n",
    "                # update current node if exceeding it's length\n",
    "                if curr_child.width() <= self.active_length:\n",
    "                    self.active_node = curr_child\n",
    "                    self.active_length -= curr_child.width()\n",
    "                    self.active_edge += curr_child.width()\n",
    "                    continue\n",
    "\n",
    "                # check if we don't have to devide current active_edge\n",
    "                if self.text[idx] == curr_char:\n",
    "                    if last_added_node is not None:\n",
    "                        last_added_node.suffix_link = self.active_node\n",
    "                    self.active_length += 1\n",
    "                    break\n",
    "\n",
    "                inner_node_end_ref = IntRef(curr_child.start + self.active_length - 1)\n",
    "                inner_node = Node(end = inner_node_end_ref, start = curr_child.start)\n",
    "                self.inner_node_cnt += 1\n",
    "                self.add_child_node(self.active_node, inner_node)\n",
    "\n",
    "                if last_added_node is not None:\n",
    "                    last_added_node.suffix_link = inner_node\n",
    "\n",
    "                curr_child.start = inner_node.end.value + 1\n",
    "                new_leaf = self.create_leaf(position)\n",
    "\n",
    "                self.add_child_node(inner_node, curr_child)\n",
    "                self.add_child_node(inner_node, new_leaf)\n",
    "\n",
    "                last_added_node = inner_node\n",
    "\n",
    "                if self.active_node is self.root:\n",
    "                    self.active_length -= 1\n",
    "                    self.active_edge += 1\n",
    "\n",
    "            self.remainder -= 1\n",
    "            if self.active_node is not self.root:\n",
    "                if self.active_node.suffix_link is not None:\n",
    "                    self.active_node = self.active_node.suffix_link\n",
    "                else:\n",
    "                    self.active_node = self.root\n",
    "\n",
    "    def find_pattern(self, pattern: str) -> list[int]:\n",
    "        \"\"\"\n",
    "        Find all occurrences of the pattern in the text.\n",
    "\n",
    "        Args:\n",
    "            pattern: The pattern to search for\n",
    "\n",
    "        Returns:\n",
    "            A list of positions where the pattern occurs in the text\n",
    "        \"\"\"\n",
    "\n",
    "        if len(pattern) == 0 or pattern[0] not in self.root.children:\n",
    "            return []\n",
    "\n",
    "        curr_node = self.root.children[pattern[0]]\n",
    "        pattern_found = True\n",
    "\n",
    "        pos = 0\n",
    "\n",
    "        for i in range(1, len(pattern)):\n",
    "            char = pattern[i]\n",
    "            pos += 1\n",
    "            if pos < curr_node.width():\n",
    "                if char != self.text[curr_node.start + pos]:\n",
    "                    pattern_found = False\n",
    "                    break\n",
    "            else:\n",
    "                if char in curr_node.children:\n",
    "                    curr_node = curr_node.children[char]\n",
    "                    pos = 0\n",
    "                else:\n",
    "                    pattern_found = False\n",
    "                    break\n",
    "\n",
    "        if not pattern_found:\n",
    "            return []\n",
    "\n",
    "        result = []\n",
    "        to_check = deque([curr_node])\n",
    "\n",
    "        while to_check:\n",
    "            node = to_check.popleft()\n",
    "\n",
    "            if not node.children:\n",
    "                result.append(node.id)\n",
    "                continue\n",
    "\n",
    "            for child_node in node.children.values():\n",
    "                to_check.append(child_node)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __print_help(self, current_node: Node, current_path: str, current_string: str):\n",
    "        next_nodes = current_node.children\n",
    "\n",
    "        if not next_nodes:\n",
    "            print(f\"current string: {current_string + self.text[current_node.start:current_node.end.value + 1]}\")\n",
    "            print(f\"current path: {current_path}\")\n",
    "            print()\n",
    "            return\n",
    "\n",
    "        for next_node in next_nodes.values():\n",
    "            self.__print_help(next_node, f\"{current_path} -> {next_node.debug_str()}\\n\", current_string + self.text[current_node.start:current_node.end.value + 1])\n",
    "\n",
    "    def print(self):\n",
    "        self.__print_help(self.root, f\"{self.root.debug_str()}\\n\", \"\")\n",
    "\n",
    "    def contains_suffix(self, suffix: str):\n",
    "        if suffix[0] not in self.root.children:\n",
    "            return False\n",
    "\n",
    "        curr_node = self.root.children[suffix[0]]\n",
    "        pos = 0\n",
    "\n",
    "        for char in suffix[1:]:\n",
    "            pos += 1\n",
    "            if pos < curr_node.width():\n",
    "                if char != self.text[curr_node.start + pos]:\n",
    "                    return False\n",
    "            else:\n",
    "                if char in curr_node.children:\n",
    "                    curr_node = curr_node.children[char]\n",
    "                    pos = 0\n",
    "                else:\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def get_leaves_cnt(self):\n",
    "        return self.leaf_cnt\n",
    "\n",
    "    def get_inner_nodes_cnt(self):\n",
    "        return self.inner_node_cnt\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.get_inner_nodes_cnt() + self.get_leaves_cnt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34566d39",
   "metadata": {},
   "source": [
    "#### Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e670039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class TestSuffixTreeBuild:\n",
    "    texts = [\"abcabx\",\n",
    "                \"abcabxabd\",\n",
    "                \"abcabxabcd\",\n",
    "                \"banan\",\n",
    "                \"niedzwiedzdzwiedz\"\n",
    "                \"x\" * 100,\n",
    "                \"ab\" * 100 + \"x\"]\n",
    "\n",
    "    def test_build_tree_single_words(self):\n",
    "\n",
    "        for text in TestSuffixTreeBuild.texts:\n",
    "            trie = SuffixTree(text)\n",
    "            assert len(trie.text) == trie.get_leaves_cnt()\n",
    "\n",
    "    # def test_build_tree_texts(self):\n",
    "    #     texts_dir = \"texts\"\n",
    "    #     path_to_dir = os.path.join(os.path.dirname(__file__), texts_dir)\n",
    "\n",
    "    #     for file_path in os.listdir(path_to_dir):\n",
    "    #         full_file_path = os.path.join(path_to_dir, file_path)\n",
    "    #         with open(full_file_path, \"r\") as file:\n",
    "    #             text = file.read()\n",
    "    #             trie = SuffixTree(text)\n",
    "    #             assert len(trie.text) == trie.get_leaves_cnt()\n",
    "\n",
    "class TestSuffixTreeFindPattern:\n",
    "    def test_find_pattern_basic(self):\n",
    "        text = \"ABABCABCABC\"\n",
    "        pattern = \"ABC\"\n",
    "        trie = SuffixTree(text)\n",
    "        result = trie.find_pattern(pattern)\n",
    "        expected = [2, 5, 8]\n",
    "        assert sorted(result) == sorted(expected), f\"Oczekiwano: {expected}, otrzymano: {result}\"\n",
    "\n",
    "    def test_find_pattern_multiple_matches(self):\n",
    "        text = \"ABABABABABA\"\n",
    "        pattern = \"ABA\"\n",
    "        trie = SuffixTree(text)\n",
    "        result = trie.find_pattern(pattern)\n",
    "        expected = [0, 2, 4, 6, 8]\n",
    "        assert sorted(result) == sorted(expected), f\"Oczekiwano: {expected}, otrzymano: {result}\"\n",
    "\n",
    "    def test_find_pattern_no_match(self):\n",
    "        text = \"ABCDEF\"\n",
    "        pattern = \"XYZ\"\n",
    "        trie = SuffixTree(text)\n",
    "        result = trie.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_empty_pattern(self):\n",
    "        text = \"ABCDEF\"\n",
    "        pattern = \"\"\n",
    "        trie = SuffixTree(text)\n",
    "        result = trie.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_empty_text(self):\n",
    "        text = \"\"\n",
    "        pattern = \"ABC\"\n",
    "        trie = SuffixTree(text)\n",
    "        result = trie.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_pattern_equals_text(self):\n",
    "        text = \"ABC\"\n",
    "        pattern = \"ABC\"\n",
    "        trie = SuffixTree(text)\n",
    "        result = trie.find_pattern(pattern)\n",
    "        expected = [0]\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_pattern_longer_than_text(self):\n",
    "        text = \"ABC\"\n",
    "        pattern = \"ABCDEF\"\n",
    "        trie = SuffixTree(text)\n",
    "        result = trie.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c37de4",
   "metadata": {},
   "source": [
    "## Zadanie wspólne podciągi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6e805",
   "metadata": {},
   "source": [
    "### Analiza złożoności\n",
    "\n",
    "Dla algortymów znajdowania wspólnego podciągu dla dwóch tekstów oraz znajdowania najdłuższego palindromicznego podciągu złożoność wynosi ```O(n)```, ponieważ tworzymy drzewo suffiksów z kombinacji tych dwóch tekstów o łącznej długości ```2 * n```. Następnie wykorzystujemy przeszukiwanie wgłąb, które odwiedza każdy węzeł dokładnie raz, więc również działa w czasie liniowym. W przypdaku algorytmu znajdowania najduższego podciągu dla ```k``` tekstów musimy połączyć z sobą wszystkie teksty przez co osiągamy złożoność ```O(n * k)```. Innymi słowy dla wszystkich tych algorytmów złożoność czasowa jest liniowa w stosunku do sumarycznej długości dostarczonych tekstów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8455a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniqueCharGenerator:\n",
    "    def __init__(self):\n",
    "        self.offset = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        char = chr(128 + self.offset)\n",
    "        self.offset += 1\n",
    "        return char\n",
    "\n",
    "def check_if_contains_all_classyfication_bits(classyfication: int, strings_cnt: int):\n",
    "    for _ in range(strings_cnt):\n",
    "        if (classyfication & 1 == 0):\n",
    "            return False\n",
    "\n",
    "        classyfication >>= 1\n",
    "\n",
    "    return True\n",
    "\n",
    "def longest_common_substring(str1: str, str2: str) -> str:\n",
    "    \"\"\"\n",
    "    Find the longest common substring of two strings using a suffix tree.\n",
    "\n",
    "    Args:\n",
    "        str1: First string\n",
    "        str2: Second string\n",
    "\n",
    "    Returns:\n",
    "        The longest common substring\n",
    "    \"\"\"\n",
    "\n",
    "    def get_node_classification(node: Node, text_depth: int = 0) -> int:\n",
    "        nonlocal str1_len, trie, max_height, substring_start_idx\n",
    "\n",
    "        if not node.children:\n",
    "            # return 2 ** (index of string in combined string) to allow bitwise or classification\n",
    "            if node.id < str1_len:\n",
    "                return 1 << 0\n",
    "            else:\n",
    "                return 1 << 1\n",
    "\n",
    "        classyfication = 0\n",
    "\n",
    "        for child_node in node.children.values():\n",
    "            child_node_width = child_node.width()\n",
    "            bits = get_node_classification(child_node, text_depth + child_node_width)\n",
    "            classyfication |= bits\n",
    "\n",
    "        if check_if_contains_all_classyfication_bits(classyfication, 2):\n",
    "            if max_height < text_depth:\n",
    "                max_height = text_depth\n",
    "                substring_start_idx = node.end.value - text_depth + 1\n",
    "\n",
    "        return classyfication\n",
    "\n",
    "    # Concatenate the strings with a unique separator\n",
    "    combined = str1 + \"#\" + str2\n",
    "\n",
    "    # Build a suffix tree for the combined string\n",
    "    trie = SuffixTree(combined)\n",
    "\n",
    "    str1_len = len(str1) + 1\n",
    "    max_height = 0\n",
    "    substring_start_idx = 0\n",
    "\n",
    "    # Traverse the tree to find the longest path that occurs in both strings\n",
    "    root_classifiaction = get_node_classification(trie.root)\n",
    "\n",
    "    if not check_if_contains_all_classyfication_bits(root_classifiaction, 2):\n",
    "        return \"\"\n",
    "\n",
    "    lcs = combined[substring_start_idx:substring_start_idx + max_height]\n",
    "\n",
    "    return lcs\n",
    "\n",
    "def longest_common_substring_multiple(strings: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Find the longest common substring among multiple strings using suffix structures.\n",
    "\n",
    "    Args:\n",
    "        strings: List of strings to compare\n",
    "\n",
    "    Returns:\n",
    "        The longest common substring that appears in all strings\n",
    "    \"\"\"\n",
    "\n",
    "    def get_node_classification(node: Node, text_depth: int = 0) -> int:\n",
    "        nonlocal string_sizes, trie, max_height, substring_start_idx\n",
    "\n",
    "        if not node.children:\n",
    "            # return 2 ** (index of string in combined string) to allow bitwise or classification\n",
    "            for str_idx, size in enumerate(string_sizes):\n",
    "                if node.id < size:\n",
    "                    return 1 << str_idx\n",
    "\n",
    "            raise Exception(\"Should never happen\")\n",
    "\n",
    "        classyfication = 0\n",
    "\n",
    "        for child_node in node.children.values():\n",
    "            child_node_width = child_node.width()\n",
    "            bits = get_node_classification(child_node, text_depth + child_node_width)\n",
    "            classyfication |= bits\n",
    "\n",
    "        if check_if_contains_all_classyfication_bits(classyfication, len(strings)):\n",
    "            if max_height < text_depth:\n",
    "                max_height = text_depth\n",
    "                substring_start_idx = node.end.value - text_depth + 1\n",
    "\n",
    "        return classyfication\n",
    "\n",
    "    if len(strings) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    # Concatenate the strings with a unique separator\n",
    "    combined = strings[0]\n",
    "    gen = UniqueCharGenerator()\n",
    "\n",
    "    string_sizes = [len(strings[0]) + 1]\n",
    "\n",
    "    for idx in range(1, len(strings)):\n",
    "        string = strings[idx]\n",
    "        combined += next(gen) + string\n",
    "\n",
    "        string_sizes.append(len(combined) + 1)\n",
    "\n",
    "    # Build a suffix tree for the combined string\n",
    "    trie = SuffixTree(combined)\n",
    "\n",
    "    max_height = 0\n",
    "    substring_start_idx = 0\n",
    "\n",
    "    # Traverse the tree to find the longest path that occurs in all strings\n",
    "    root_classifiaction = get_node_classification(trie.root)\n",
    "\n",
    "    if not check_if_contains_all_classyfication_bits(root_classifiaction, len(strings)):\n",
    "        return \"\"\n",
    "\n",
    "    lcs = combined[substring_start_idx:substring_start_idx + max_height]\n",
    "\n",
    "    return lcs\n",
    "\n",
    "def longest_palindromic_substring(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Find the longest palindromic substring in a given text using suffix structures.\n",
    "\n",
    "    Args:\n",
    "        text: Input text\n",
    "\n",
    "    Returns:\n",
    "        The longest palindromic substring\n",
    "    \"\"\"\n",
    "\n",
    "    def get_node_classification(node: Node, text_depth: int = 0) -> int:\n",
    "        nonlocal str1_len, trie, max_height, substring_start_idx\n",
    "\n",
    "        if not node.children:\n",
    "            # return 2 ** (index of string in combined string) to allow bitwise or classification\n",
    "            if node.id < str1_len:\n",
    "                forward_indices[node] = {node.id}\n",
    "                reverse_indices[node] = set()\n",
    "                return 1 << 0\n",
    "            else:\n",
    "                forward_indices[node] = set()\n",
    "                reverse_indices[node] = {node.id - str1_len}\n",
    "                return 1 << 1\n",
    "\n",
    "        classyfication = 0\n",
    "\n",
    "        forward_indices[node] = set()\n",
    "        reverse_indices[node] = set()\n",
    "\n",
    "        for child_node in node.children.values():\n",
    "            child_node_width = child_node.width()\n",
    "            bits = get_node_classification(child_node, text_depth + child_node_width)\n",
    "            classyfication |= bits\n",
    "            forward_indices[node] |= forward_indices[child_node]\n",
    "            reverse_indices[node] |= reverse_indices[child_node]\n",
    "\n",
    "        # if check_if_contains_all_classyfication_bits(classyfication, 2):\n",
    "        if max_height < text_depth and forward_indices[node] and reverse_indices[node]:\n",
    "            for forward_idx in forward_indices[node]:\n",
    "                reverse_idx = (str1_len - 2) - (forward_idx + text_depth - 1)\n",
    "\n",
    "                if reverse_idx in reverse_indices[node]:\n",
    "                    max_height = text_depth\n",
    "                    substring_start_idx = node.end.value - text_depth + 1\n",
    "                    break\n",
    "\n",
    "        return classyfication\n",
    "\n",
    "    str1 = text\n",
    "    str2 = text[::-1]\n",
    "    # Concatenate the strings with a unique separator\n",
    "    combined = str1 + \"#\" + str2\n",
    "\n",
    "    # Build a suffix tree for the combined string\n",
    "    trie = SuffixTree(combined)\n",
    "\n",
    "    str1_len = len(str1) + 1\n",
    "    max_height = 0\n",
    "    substring_start_idx = 0\n",
    "\n",
    "    forward_indices = {}\n",
    "    reverse_indices = {}\n",
    "\n",
    "    # Traverse the tree to find the longest path that occurs in both strings\n",
    "    get_node_classification(trie.root)\n",
    "\n",
    "    lcs = combined[substring_start_idx:substring_start_idx + max_height]\n",
    "\n",
    "    return lcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe53153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_substring_dp(tab1, tab2):\n",
    "    n1 = len(tab1)\n",
    "    n2 = len(tab2)\n",
    "\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return \"\"\n",
    "\n",
    "    lcsTab = [[0 for _ in range(n2)] for _ in range(n1)]\n",
    "\n",
    "    for R in range(n1):\n",
    "        lcsTab[R][0] = 1 if tab1[R] == tab2[0] else 0\n",
    "\n",
    "    for C in range(n2):\n",
    "        lcsTab[0][C] = 1 if tab1[0] == tab2[C] else 0\n",
    "\n",
    "    for R in range(1, n1):\n",
    "        for C in range(1, n2):\n",
    "            lcsTab[R][C] = max(lcsTab[R - 1][C], lcsTab[R][C - 1])\n",
    "            if tab1[R] == tab2[C]:\n",
    "                lcsTab[R][C] = max(lcsTab[R][C], lcsTab[R - 1][C - 1] + 1)\n",
    "\n",
    "    return get_sequence(lcsTab, tab1)\n",
    "\n",
    "def get_sequence(lcsTab, tab1):\n",
    "    sequence = []\n",
    "\n",
    "    R = len(lcsTab) - 1\n",
    "    C = len(lcsTab[0]) - 1\n",
    "\n",
    "    while R != 0 and C != 0:\n",
    "        if lcsTab[R][C] == lcsTab[R][C - 1]:\n",
    "            C -= 1\n",
    "        elif lcsTab[R][C] == lcsTab[R - 1][C]:\n",
    "            R -= 1\n",
    "        else:\n",
    "            sequence.append(tab1[R])\n",
    "            R -= 1\n",
    "            C -= 1\n",
    "\n",
    "    if lcsTab[R][C] == 1:\n",
    "        sequence.append(tab1[R])\n",
    "\n",
    "    sequence.reverse()\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26ab546",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sizes = [5, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "suffix_tree_exec_times = []\n",
    "dp_exec_times = []\n",
    "\n",
    "for size in text_sizes:\n",
    "    text1 = get_random_text(size)\n",
    "    text2 = get_random_text(size)\n",
    "    suffix_tree_exec_times.append(measure_execution_time(longest_common_substring, text1, text2))\n",
    "    dp_exec_times.append(measure_execution_time(longest_common_substring_dp, text1, text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4512e782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Longest common substring\")\n",
    "plt.scatter(text_sizes, suffix_tree_exec_times, c = 'red', label = \"suffix tree\")\n",
    "plt.scatter(text_sizes, dp_exec_times, c = 'blue', label = \"dynamic programming\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c7987",
   "metadata": {},
   "source": [
    "#### Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b6f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLCS:\n",
    "    def test_basic_overlap(self):\n",
    "        assert longest_common_substring(\"banana\", \"ananas\") == \"anana\"\n",
    "\n",
    "    def test_no_overlap(self):\n",
    "        assert longest_common_substring(\"abc\", \"xyz\") == \"\"\n",
    "\n",
    "    def test_full_match(self):\n",
    "        assert longest_common_substring(\"hello\", \"hello\") == \"hello\"\n",
    "\n",
    "    def test_empty_strings(self):\n",
    "        assert longest_common_substring(\"\", \"\") == \"\"\n",
    "        assert longest_common_substring(\"abc\", \"\") == \"\"\n",
    "        assert longest_common_substring(\"\", \"abc\") == \"\"\n",
    "\n",
    "    def test_multiple_common_substrings(self):\n",
    "        # Both \"abc\" and \"bca\" are common, but \"abc\" appears first\n",
    "        assert longest_common_substring(\"abcabc\", \"bcaabc\") in {\"abc\", \"bca\"}\n",
    "\n",
    "    def test_case_sensitivity(self):\n",
    "        assert longest_common_substring(\"ABC\", \"abc\") == \"\"\n",
    "\n",
    "    def test_longest_at_end(self):\n",
    "        assert longest_common_substring(\"xyzabc\", \"defabc\") == \"abc\"\n",
    "\n",
    "    def test_longest_at_start(self):\n",
    "        assert longest_common_substring(\"abcdef\", \"abcxyz\") == \"abc\"\n",
    "\n",
    "class TestLCSMultiple:\n",
    "    def test_basic_overlap(self):\n",
    "        assert longest_common_substring_multiple([\"banana\", \"ananas\", \"canada\"]) == \"ana\"\n",
    "\n",
    "    def test_no_common_substring(self):\n",
    "        assert longest_common_substring_multiple([\"abc\", \"def\", \"ghi\"]) == \"\"\n",
    "\n",
    "    def test_full_match(self):\n",
    "        assert longest_common_substring_multiple([\"hello\", \"hello\", \"hello\"]) == \"hello\"\n",
    "\n",
    "    def test_empty_strings(self):\n",
    "        assert longest_common_substring_multiple([\"\", \"abc\", \"def\"]) == \"\"\n",
    "        assert longest_common_substring_multiple([\"\", \"\", \"\"]) == \"\"\n",
    "\n",
    "    def test_common_at_end(self):\n",
    "        assert longest_common_substring_multiple([\"xyzabc\", \"defabc\", \"123abc\"]) == \"abc\"\n",
    "\n",
    "    def test_common_at_start(self):\n",
    "        assert longest_common_substring_multiple([\"abcdef\", \"abcxyz\", \"abcpqr\"]) == \"abc\"\n",
    "\n",
    "    def test_case_sensitivity(self):\n",
    "        assert longest_common_substring_multiple([\"ABC\", \"abc\", \"Abc\"]) == \"\"\n",
    "\n",
    "    def test_multiple_candidates(self):\n",
    "        # Both \"ab\" and \"bc\" are common, but \"ab\" appears first in all\n",
    "        assert longest_common_substring_multiple([\"abxcaxbc\", \"zabcz\", \"12abc34\"]) in {\"ab\", \"bc\"}\n",
    "\n",
    "    def test_overlap_a_lot_of_texts(self):\n",
    "        assert longest_common_substring_multiple([\"banana\", \"ananas\", \"canada\", \"kanapa\", \"x\" * 8 + \"ana\" + \"x\" * 8]) == \"ana\"\n",
    "\n",
    "class TestLPS:\n",
    "    def test_basic_palindrome(self):\n",
    "        assert longest_palindromic_substring(\"babad\") in {\"bab\", \"aba\"}\n",
    "\n",
    "    def test_even_length_palindrome(self):\n",
    "        assert longest_palindromic_substring(\"cbbd\") == \"bb\"\n",
    "\n",
    "    def test_reverse_substring_longer_than_palindromic_substring(self):\n",
    "        assert longest_palindromic_substring(\"abacdfgdcaba\") == \"aba\"\n",
    "        assert longest_palindromic_substring(\"pqqpabcdfghfdcba\") == \"pqqp\"\n",
    "\n",
    "    def test_full_string_palindrome(self):\n",
    "        assert longest_palindromic_substring(\"racecar\") == \"racecar\"\n",
    "        assert longest_palindromic_substring(\"a\"*20) == \"a\"*20\n",
    "\n",
    "    def test_single_character(self):\n",
    "        assert longest_palindromic_substring(\"a\") == \"a\"\n",
    "\n",
    "    def test_empty_string(self):\n",
    "        assert longest_palindromic_substring(\"\") == \"\"\n",
    "\n",
    "    def test_no_palindrome_longer_than_one(self):\n",
    "        assert longest_palindromic_substring(\"abcde\") in {\"a\", \"b\", \"c\", \"d\", \"e\"}\n",
    "\n",
    "    def test_palindrome_at_start(self):\n",
    "        assert longest_palindromic_substring(\"racecarxyz\") == \"racecar\"\n",
    "\n",
    "    def test_palindrome_at_end(self):\n",
    "        assert longest_palindromic_substring(\"xyzracecar\") == \"racecar\"\n",
    "\n",
    "    def test_multiple_same_length(self):\n",
    "        assert longest_palindromic_substring(\"bccbabaab\") in {\"bccb\", \"baab\"}\n",
    "\n",
    "    def test_case_sensitivity(self):\n",
    "        assert longest_palindromic_substring(\"Aa\") in {\"A\", \"a\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82a151",
   "metadata": {},
   "source": [
    "# Zadanie Sufiksy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7acb7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "def sorted_search(tab, val, key=lambda x: x, side = 'left'):\n",
    "    beg, end = 0, len(tab) - 1\n",
    "    while beg <= end:\n",
    "        mid = (beg + end) // 2\n",
    "        if val == key(tab[mid]):\n",
    "            if side == 'left':\n",
    "                end = mid - 1\n",
    "            elif side == 'right':\n",
    "                beg = mid + 1\n",
    "            else:\n",
    "                raise Exception(f\"Incorrect side argument: {side}\")\n",
    "        elif val < key(tab[mid]):\n",
    "            end = mid - 1\n",
    "        else:\n",
    "            beg = mid + 1\n",
    "    return beg\n",
    "\n",
    "class Suffix:\n",
    "    def __init__(self, suffix: str, idx: int):\n",
    "        self.suffix = suffix\n",
    "        self.idx = idx\n",
    "\n",
    "class SuffixArray:\n",
    "    def __init__(self, text: str) -> None:\n",
    "        self.suffixes = [0] * len(text)\n",
    "        self.text = text\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        suffixes = [Suffix(self.text[idx:], idx) for idx in range(len(self.text))]\n",
    "        suffixes.sort(key = lambda suff: suff.suffix)\n",
    "\n",
    "        for i, suff in enumerate(suffixes):\n",
    "            self.suffixes[i] = suff.idx\n",
    "\n",
    "    def suffix(self, idx: int):\n",
    "        return self.text[idx:]\n",
    "\n",
    "    def find_pattern(self, pattern: str):\n",
    "        if len(pattern) == 0:\n",
    "            return []\n",
    "\n",
    "        key_function = lambda x: self.suffix(x)[:len(pattern)]\n",
    "        il = sorted_search(self.suffixes, pattern, key = key_function, side = 'left')\n",
    "        ir = sorted_search(self.suffixes, pattern, key = key_function, side = 'right')\n",
    "\n",
    "        return self.suffixes[il:ir]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc88681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "def measure_params(func: Callable[[str], object], *func_args) -> dict[str, float]:\n",
    "    start_time = time.perf_counter()\n",
    "    mem_usage, obj = memory_usage((func, func_args), retval=True)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    return {\n",
    "            \"construction_time_ms\": (end_time - start_time) * 1000,\n",
    "            \"memory_usage_kb\": (max(mem_usage) - min(mem_usage)) * 1024,\n",
    "            \"size\": len(obj)\n",
    "           }\n",
    "\n",
    "\n",
    "def compare_suffix_structures(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compare suffix array and suffix tree data structures.\n",
    "\n",
    "    Args:\n",
    "        text: The input text for which to build the structures\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing:\n",
    "        - Construction time for both structures\n",
    "        - Memory usage for both structures\n",
    "        - Size (number of nodes/elements) of both structures\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "        \"suffix_array\": measure_params(SuffixArray, text),\n",
    "        \"suffix_tree\": measure_params(SuffixTree, text)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc968cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_sizes = [5, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "suffix_tree_params = []\n",
    "suffix_array_params = []\n",
    "\n",
    "for size in text_sizes:\n",
    "    text = get_random_text(size)\n",
    "    cmp_dict = compare_suffix_structures(text)\n",
    "    suffix_tree_exec_times.append(cmp_dict[\"suffix_tree\"])\n",
    "    dp_exec_times.append(cmp_dict[\"suffix_array\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342eea17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87d6efd0",
   "metadata": {},
   "source": [
    "#### Testy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSuffixTreeFindPattern:\n",
    "    def test_find_pattern_basic(self):\n",
    "        text = \"ABABCABCABC\"\n",
    "        pattern = \"ABC\"\n",
    "        suff_array = SuffixArray(text)\n",
    "        result = suff_array.find_pattern(pattern)\n",
    "        expected = [2, 5, 8]\n",
    "        assert sorted(result) == sorted(expected), f\"Oczekiwano: {expected}, otrzymano: {result}\"\n",
    "\n",
    "    def test_find_pattern_multiple_matches(self):\n",
    "        text = \"ABABABABABA\"\n",
    "        pattern = \"ABA\"\n",
    "        suff_array = SuffixArray(text)\n",
    "        result = suff_array.find_pattern(pattern)\n",
    "        expected = [0, 2, 4, 6, 8]\n",
    "        assert sorted(result) == sorted(expected), f\"Oczekiwano: {expected}, otrzymano: {result}\"\n",
    "\n",
    "    def test_find_pattern_no_match(self):\n",
    "        text = \"ABCDEF\"\n",
    "        pattern = \"XYZ\"\n",
    "        suff_array = SuffixArray(text)\n",
    "        result = suff_array.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_empty_pattern(self):\n",
    "        text = \"ABCDEF\"\n",
    "        pattern = \"\"\n",
    "        suff_array = SuffixArray(text)\n",
    "        result = suff_array.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_empty_text(self):\n",
    "        text = \"\"\n",
    "        pattern = \"ABC\"\n",
    "        suff_array = SuffixArray(text)\n",
    "        result = suff_array.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_pattern_equals_text(self):\n",
    "        text = \"ABC\"\n",
    "        pattern = \"ABC\"\n",
    "        suff_array = SuffixArray(text)\n",
    "        result = suff_array.find_pattern(pattern)\n",
    "        expected = [0]\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n",
    "\n",
    "    def test_find_pattern_pattern_longer_than_text(self):\n",
    "        text = \"ABC\"\n",
    "        pattern = \"ABCDEF\"\n",
    "        suff_array = SuffixArray(text)\n",
    "        result = suff_array.find_pattern(pattern)\n",
    "        expected = []\n",
    "        assert sorted(result) == sorted(expected), f\"Expected: {expected}, got: {result}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc541429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_manual_tests():\n",
    "    test_classes = [\n",
    "        TestSuffixTreeBuild(),\n",
    "        TestSuffixTreeFindPattern(),\n",
    "        TestLCS(),\n",
    "        TestLCSMultiple(),\n",
    "        TestLPS(),\n",
    "        TestSuffixTreeFindPattern()\n",
    "    ]\n",
    "    total = 0\n",
    "    passed = 0\n",
    "    for test_class in test_classes:\n",
    "        for attr in dir(test_class):\n",
    "            if attr.startswith(\"test_\"):\n",
    "                total += 1\n",
    "                try:\n",
    "                    getattr(test_class, attr)()\n",
    "                    print(f\"{test_class.__class__.__name__}.{attr}: PASSED\")\n",
    "                    passed += 1\n",
    "                except AssertionError as e:\n",
    "                    print(f\"{test_class.__class__.__name__}.{attr}: FAILED\\n  {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"{test_class.__class__.__name__}.{attr}: ERROR\\n  {e}\")\n",
    "\n",
    "    print(f\"\\n{passed}/{total} tests passed.\")\n",
    "\n",
    "run_all_manual_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021e3b3",
   "metadata": {},
   "source": [
    "# Zadanie Porównanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad41d09",
   "metadata": {},
   "source": [
    "### 1. Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_texts(text1, text2):\n",
    "    if len(text1) != len(text2):\n",
    "        return False, 0\n",
    "\n",
    "    char_cmp_cnt = 0\n",
    "    for i in range(len(text1)):\n",
    "        char_cmp_cnt += 1\n",
    "        if text1[i] != text2[i]:\n",
    "            return False, char_cmp_cnt\n",
    "\n",
    "    return True, char_cmp_cnt\n",
    "\n",
    "def naive_pattern_match(text: str, pattern: str) -> tuple[list[int], int]:\n",
    "    text_len = len(text)\n",
    "    pattern_len = len(pattern)\n",
    "    char_cmp_cnt = 0\n",
    "\n",
    "    if pattern_len == 0 or pattern_len > text_len:\n",
    "        return [], 0\n",
    "\n",
    "    result = []\n",
    "    for i in range(text_len):\n",
    "        # if text[i:min(i + pattern_len, text_len)] == pattern:\n",
    "        are_the_same, common_prefix_length = cmp_texts(text[i:min(i + pattern_len, text_len)], pattern)\n",
    "        char_cmp_cnt += common_prefix_length\n",
    "        if are_the_same:\n",
    "            result.append(i)\n",
    "\n",
    "    return result, char_cmp_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387d9b2",
   "metadata": {},
   "source": [
    "### 2. KMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lps_array(pattern: str) -> tuple[list[int], int]:\n",
    "    lps = [0] * len(pattern)\n",
    "    length = 0  # Length of the previous longest prefix suffix\n",
    "    i = 1\n",
    "\n",
    "    char_cmp_count = 0\n",
    "\n",
    "    while i < len(pattern):\n",
    "        char_cmp_count += 1\n",
    "        if pattern[i] == pattern[length]:\n",
    "            length += 1\n",
    "            lps[i] = length\n",
    "            i += 1\n",
    "        else:\n",
    "            if length != 0:\n",
    "                length = lps[length - 1]\n",
    "            else:\n",
    "                lps[i] = 0\n",
    "                i += 1\n",
    "\n",
    "    return lps, char_cmp_count\n",
    "\n",
    "def kmp_pattern_match(text: str, pattern: str) -> tuple[list[int], int]:\n",
    "    text_len = len(text)\n",
    "    pattern_len = len(pattern)\n",
    "\n",
    "    if text_len < pattern_len or pattern_len == 0:\n",
    "        return [], 0\n",
    "\n",
    "    result = []\n",
    "\n",
    "    p, char_cmp_count = compute_lps_array(pattern)\n",
    "    j = 0\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        char_cmp_count += 1\n",
    "        while j > 0 and text[i] != pattern[j]:\n",
    "            char_cmp_count += 1\n",
    "            j = p[j - 1]\n",
    "\n",
    "        char_cmp_count += 1\n",
    "        if text[i] == pattern[j]:\n",
    "            j += 1\n",
    "\n",
    "        if j == len(pattern):\n",
    "            result.append(i - len(pattern) + 1)\n",
    "            j = p[j - 1]\n",
    "\n",
    "    return result, char_cmp_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f62017",
   "metadata": {},
   "source": [
    "### 3. Boyer-Moore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bad_character_table(pattern: str) -> dict:\n",
    "    rightmost_occurences = {}\n",
    "    for i, char in enumerate(pattern):\n",
    "        rightmost_occurences[char] = i\n",
    "\n",
    "    return rightmost_occurences\n",
    "\n",
    "def compute_good_suffix_table(pattern: str) -> tuple[list[int], int]:\n",
    "    pattern_len = len(pattern)\n",
    "    good_suffix_table = [0] * (pattern_len + 1)\n",
    "    border_pos = [0] * (pattern_len + 1)\n",
    "\n",
    "    i = pattern_len\n",
    "    j = pattern_len + 1\n",
    "    border_pos[i] = j\n",
    "\n",
    "    char_cmp_cnt = 0\n",
    "\n",
    "    while i > 0:\n",
    "        char_cmp_cnt += 1\n",
    "        while j <= pattern_len and pattern[i - 1] != pattern[j - 1]:\n",
    "            char_cmp_cnt += 1\n",
    "            if good_suffix_table[j] == 0:\n",
    "                good_suffix_table[j] = j - i\n",
    "            j = border_pos[j]\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "        border_pos[i] = j\n",
    "\n",
    "    j = border_pos[0]\n",
    "    for i in range(pattern_len + 1):\n",
    "        if good_suffix_table[i] == 0:\n",
    "            good_suffix_table[i] = j\n",
    "        if i == j:\n",
    "            j = border_pos[j]\n",
    "\n",
    "    return good_suffix_table, char_cmp_cnt\n",
    "\n",
    "def boyer_moore_pattern_match(text: str, pattern: str) -> tuple[list[int], int]:\n",
    "    text_len = len(text)\n",
    "    pattern_len = len(pattern)\n",
    "\n",
    "    if pattern_len == 0 or text_len < pattern_len:\n",
    "        return [], 0\n",
    "\n",
    "    bad_char_table = compute_bad_character_table(pattern)\n",
    "    good_suffix_table, char_cmp_cnt = compute_good_suffix_table(pattern)\n",
    "    char_cmp_cnt += len(pattern) # add comparisions from 'compute_bad_character_table(pattern)' call\n",
    "\n",
    "    result = []\n",
    "    i = 0\n",
    "\n",
    "    while i <= text_len - pattern_len:\n",
    "        j = pattern_len - 1\n",
    "\n",
    "        char_cmp_cnt += 1\n",
    "        while j >= 0 and pattern[j] == text[i + j]:\n",
    "            char_cmp_cnt += 1\n",
    "            j -= 1\n",
    "\n",
    "        if j < 0:\n",
    "            result.append(i)\n",
    "\n",
    "            i += good_suffix_table[0]\n",
    "        else:\n",
    "            bad_char_shift = j - bad_char_table.get(text[i + j], -1)\n",
    "            good_suffix_shift = good_suffix_table[j + 1]\n",
    "            i += max(bad_char_shift, good_suffix_shift)\n",
    "\n",
    "    return result, char_cmp_cnt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8392f9",
   "metadata": {},
   "source": [
    "### 4. Rabin-Karp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_texts(text1, text2):\n",
    "    if len(text1) != len(text2):\n",
    "        return False, 0\n",
    "\n",
    "    char_cmp_cnt = 0\n",
    "    for i in range(len(text1)):\n",
    "        char_cmp_cnt += 1\n",
    "        if text1[i] != text2[i]:\n",
    "            return False, char_cmp_cnt\n",
    "\n",
    "    return True, char_cmp_cnt\n",
    "\n",
    "def hash_byte(curr_hash: int, byte: int, mod: int = 101):\n",
    "    return (curr_hash + byte) % mod\n",
    "\n",
    "def unhash_byte(curr_hash: int, byte: int, mod: int = 101):\n",
    "    return (curr_hash - byte + mod) % mod\n",
    "\n",
    "def hash_string(substr: str, mod: int = 101):\n",
    "    hash_res = 0\n",
    "    for char in substr:\n",
    "        hash_res = hash_byte(hash_res, ord(char), mod)\n",
    "\n",
    "    return hash_res\n",
    "\n",
    "def rabin_karp_pattern_match(text: str, pattern: str, prime: int = 101) -> tuple[list[int], int]:\n",
    "    result = []\n",
    "    text_len = len(text)\n",
    "    pattern_len = len(pattern)\n",
    "\n",
    "    if pattern_len == 0 or text_len < pattern_len:\n",
    "        return [], 0\n",
    "\n",
    "    pattern_hash = hash_string(pattern, prime)\n",
    "    curr_hash = hash_string(text[:pattern_len], prime)\n",
    "\n",
    "    char_cmp_cnt = 0\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if curr_hash == pattern_hash and text[i:i+pattern_len] == pattern:\n",
    "            are_the_same, common_prefix_length = cmp_texts(text[i:i+pattern_len], pattern)\n",
    "            char_cmp_cnt += common_prefix_length\n",
    "            if are_the_same:\n",
    "                result.append(i)\n",
    "\n",
    "        if text_len <= i + pattern_len:\n",
    "            break\n",
    "\n",
    "        curr_hash = hash_byte(curr_hash, ord(text[i+pattern_len]))\n",
    "        curr_hash = unhash_byte(curr_hash, ord(text[i]), prime)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return result, char_cmp_cnt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2dd1a",
   "metadata": {},
   "source": [
    "### 5. Aho-Corasick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from collections import deque\n",
    "from typing import List, Tuple, Optional\n",
    "from overrides import override\n",
    "\n",
    "class AhoCorasickNode:\n",
    "    def __init__(self, character: str, node_depth: int, is_terminal_node: bool = False):\n",
    "        self.character: str = character\n",
    "        self.goto_nodes: dict[str, AhoCorasickNode] = {}\n",
    "        self.fail_link: Optional[AhoCorasickNode] = None\n",
    "        self.output_link: Optional[AhoCorasickNode] = None\n",
    "        self.node_depth: int = node_depth\n",
    "        self.is_terminal_node: bool = is_terminal_node\n",
    "        self.pattern: str = \"\"\n",
    "\n",
    "    def get_character(self):\n",
    "        return self.character\n",
    "\n",
    "    def goto(self, character: str) -> Optional[AhoCorasickNode]:\n",
    "        return self.goto_nodes.get(character, None)\n",
    "\n",
    "    def fail(self) -> Optional[AhoCorasickNode]:\n",
    "        return self.fail_link\n",
    "\n",
    "    def output(self) -> Optional[AhoCorasickNode]:\n",
    "        return self.output_link\n",
    "\n",
    "    def depth(self) -> int:\n",
    "        return self.node_depth\n",
    "\n",
    "    def is_terminal(self) -> bool:\n",
    "        return self.is_terminal_node\n",
    "\n",
    "    def add_goto(self, character: str, goto_node: AhoCorasickNode):\n",
    "        assert character not in self.goto_nodes, f\"goto node for character={character} already defined!!!\"\n",
    "\n",
    "        self.goto_nodes[character] = goto_node\n",
    "\n",
    "    def set_fail(self, fail_node: Optional[AhoCorasickNode]):\n",
    "        self.fail_link = fail_node\n",
    "\n",
    "    def set_output(self, output_node: Optional[AhoCorasickNode]):\n",
    "        self.output_link = output_node\n",
    "\n",
    "    def set_is_terminal(self, is_terminal_node: bool):\n",
    "        self.is_terminal_node = is_terminal_node\n",
    "\n",
    "    def set_pattern(self, pattern: str):\n",
    "        self.pattern = pattern\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'AhoCorasickNode(\\'{self.character}\\', {self.node_depth}, is_terminal={self.is_terminal_node}, ' + \\\n",
    "            f'fail=({None if self.fail_link is None else f\"{self.fail_link.get_character()}, {self.fail_link.depth()}\"}), ' + \\\n",
    "            f'output=({None if self.output_link is None else f\"{self.output_link.get_character()}, {self.output_link.depth()}\"}))'\n",
    "\n",
    "class AhoCorasickRootNode(AhoCorasickNode):\n",
    "    def __init__(self):\n",
    "        super().__init__('', 0, is_terminal_node = False)\n",
    "\n",
    "    @override\n",
    "    def goto(self, character: str) -> Optional[AhoCorasickNode]:\n",
    "        if character not in self.goto_nodes:\n",
    "            return self\n",
    "\n",
    "        return super().goto(character)\n",
    "\n",
    "class AhoCorasick:\n",
    "    def __init__(self, patterns: List[str]):\n",
    "        self.patterns = list(filter(lambda x: len(x) > 0, patterns))\n",
    "        self.root: AhoCorasickNode = AhoCorasickRootNode()\n",
    "        self._build_trie()\n",
    "        self._build_failure_links()\n",
    "\n",
    "    def _build_trie(self):\n",
    "        for pattern in self.patterns:\n",
    "            char = pattern[0]\n",
    "\n",
    "            if self.root.goto(char) == self.root:\n",
    "                new_node = AhoCorasickNode(char, 1, is_terminal_node = len(pattern) == 1)\n",
    "                self.root.add_goto(char, new_node)\n",
    "\n",
    "        for pattern in self.patterns:\n",
    "            current_node = self.root\n",
    "\n",
    "            for depth, char in enumerate(pattern, start = 1):\n",
    "                next_node = current_node.goto(char)\n",
    "\n",
    "                if next_node is None:\n",
    "                    next_node = AhoCorasickNode(char, depth)\n",
    "                    current_node.add_goto(char, next_node)\n",
    "\n",
    "                current_node = next_node\n",
    "\n",
    "            current_node.set_is_terminal(True)\n",
    "            current_node.set_pattern(pattern)\n",
    "\n",
    "    def _build_failure_links(self):\n",
    "        queue: deque[AhoCorasickNode] = deque([self.root])\n",
    "\n",
    "        while queue:\n",
    "            current_node = queue.popleft()\n",
    "\n",
    "            for char, goto_node in current_node.goto_nodes.items():\n",
    "                queue.append(goto_node)\n",
    "\n",
    "                if current_node is self.root:\n",
    "                    goto_node.set_fail(self.root)\n",
    "\n",
    "                fail_node = current_node.fail()\n",
    "\n",
    "                while fail_node is not None and fail_node is not self.root and fail_node.goto(char) is None:\n",
    "                    fail_node = fail_node.fail()\n",
    "\n",
    "                if fail_node is not None and fail_node.goto(char) is not None:\n",
    "                    goto_node.set_fail(fail_node.goto(char))\n",
    "                else:\n",
    "                    goto_node.set_fail(self.root)\n",
    "\n",
    "            output_node = current_node.fail()\n",
    "\n",
    "            while output_node is not None and not output_node.is_terminal():\n",
    "                output_node = output_node.fail()\n",
    "\n",
    "            current_node.set_output(output_node)\n",
    "\n",
    "    def search(self, text: str) -> Tuple[List[int], int]:\n",
    "        char_cmp_cnt = 0\n",
    "        result = []\n",
    "\n",
    "        current_node: AhoCorasickNode = self.root\n",
    "\n",
    "        for position, char in enumerate(text):\n",
    "            char_cmp_cnt += 1\n",
    "            while current_node.goto(char) is None:\n",
    "                char_cmp_cnt += 1\n",
    "                current_node = current_node.fail()\n",
    "\n",
    "            current_node = current_node.goto(char)\n",
    "\n",
    "            if current_node.is_terminal():\n",
    "                result.append(position - current_node.depth() + 1)\n",
    "\n",
    "            output_node = current_node.output()\n",
    "\n",
    "            while output_node is not None:\n",
    "                result.append(position - output_node.depth() + 1)\n",
    "                output_node = output_node.output()\n",
    "\n",
    "        return result, char_cmp_cnt\n",
    "\n",
    "    def __print_help(self, current_node: AhoCorasickNode, current_path: str, current_string: str):\n",
    "        next_nodes = current_node.goto_nodes\n",
    "\n",
    "        if not next_nodes:\n",
    "            print(f\"current string: {current_string}\")\n",
    "            print(f\"current path: {current_path}\")\n",
    "            print()\n",
    "            return\n",
    "\n",
    "        for char, next_node in next_nodes.items():\n",
    "            self.__print_help(next_node, f\"{current_path} -> {next_node}\\n\", current_string + char)\n",
    "\n",
    "    def print(self):\n",
    "        self.__print_help(self.root, f\"{self.root}\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122db64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from typing import Callable\n",
    "\n",
    "def compare_pattern_matching_algorithms(text: str, pattern: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compare the performance of different pattern matching algorithms.\n",
    "\n",
    "    Args:\n",
    "        text: The text to search in\n",
    "        pattern: The pattern to search for\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the results of each algorithm:\n",
    "        - Execution time in milliseconds\n",
    "        - Memory usage in kilobytes\n",
    "        - Number of character comparisons made\n",
    "        - Positions where the pattern was found\n",
    "    \"\"\"\n",
    "    def measure_params(func: Callable[[str, str], tuple[list[int], int]] | Callable[[str], tuple[list[int], int]], *func_args) -> dict[str, float]:\n",
    "        start_time = time.perf_counter()\n",
    "        mem_usage, res = memory_usage((func, func_args), retval=True)\n",
    "        end_time = time.perf_counter()\n",
    "        pattern_found, char_cmp_cnt = res\n",
    "\n",
    "        return {\n",
    "            \"exec_time\": (end_time - start_time) * 1000,\n",
    "            \"mem_usage\": (max(mem_usage) - min(mem_usage)) * 1024,\n",
    "            \"char_cmp_cnt\": char_cmp_cnt,\n",
    "            \"pattern_found\": pattern_found\n",
    "        }\n",
    "\n",
    "    args = text, pattern\n",
    "\n",
    "    aho_corasick = AhoCorasick([pattern])\n",
    "    suff_arr = SuffixArray(text)\n",
    "    suff_tree = SuffixTree(text)\n",
    "\n",
    "    return {\n",
    "        \"naive\": measure_params(naive_pattern_match, *args),\n",
    "        \"kmp\": measure_params(kmp_pattern_match, *args),\n",
    "        \"boyer-moore\": measure_params(boyer_moore_pattern_match, *args),\n",
    "        \"rabin-karp\": measure_params(rabin_karp_pattern_match, *args),\n",
    "        \"aho-corasick\": measure_params(aho_corasick.search, text),\n",
    "        \"suffix-array\": measure_params(suff_arr.find_pattern, pattern),\n",
    "        \"suffix-tree\": measure_params(suff_tree.find_pattern, pattern),\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_algorithms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
